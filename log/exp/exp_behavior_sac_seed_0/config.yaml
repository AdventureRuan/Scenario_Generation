scenario_type_dir: safebench/scenario/config/scenario_type
scenario_type: adv_behavior_single.json
scenario_category: planning
policy_type: sac
route_dir: safebench/scenario/scenario_data/route2
scenario_id: 6
route_id: 4
ego_action_dim: 2
ego_state_dim: 4
ego_action_limit: 1.0
scenario_state_dim: 18
scenario_action_dim: 1
model_path: safebench/scenario/scenario_data/model_ckpt/sac
model_id: 1
train_episode: 2000
save_freq: 1
eval_in_train_freq: 10
buffer_capacity: 10000
buffer_start_training: 100
lr: 0.0005
tau: 0.005
update_iteration: 3
gamma: 0.99
batch_size: 32
min_Val: 1.0e-07
exp_name: exp
output_dir: log
ROOT_DIR: /home/adventure/llm_generate/SafeBench
max_episode_step: 300
auto_ego: false
mode: train_scenario
agent_cfg:
- behavior.yaml
scenario_cfg:
- sac.yaml
continue_agent_training: false
continue_scenario_training: false
seed: 0
threads: 4
device: cuda:1
num_scenario: 1
save_video: false
render: true
frame_skip: 1
port: 2000
tm_port: 8000
fixed_delta_seconds: 0.1
rl_config:
    phys_safe:
        a_lon_dec_av: 4.0
        a_lon_dec_npc: 4.0
        a_lat_dec_av: 1.5
        a_lat_dec_npc: 1.5
        eps: 0.0001
        INF_DIST: 10000
        th_same_dir: 30
        th_oppo_dir: 150
        min_lat_safe: 0.3
    adv_reward:
        w_ttc: 0.7
        w_headway: 0.3
        ttc_horizon: 3.0
        desired_headway: 1.8
    scenario_reward:
        w_phys: 1.0
        w_adv: 3.0
